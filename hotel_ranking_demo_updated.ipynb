{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel Ranking System Demo\n",
    "\n",
    "This notebook demonstrates the hotel ranking system for day-access amenities. It shows how to:\n",
    "\n",
    "1. Generate synthetic data\n",
    "2. Explore the data\n",
    "3. Train a ranking model\n",
    "4. Evaluate the model\n",
    "5. Use the model for ranking venues\n",
    "6. Perform monthly evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install pdm\n",
    "!pdm install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We'll generate a dataset spanning 3 years, with the latest year used for monthly evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if data already exists\n",
    "data_dir = \"data\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Generating data...\")\n",
    "    from src.data_generation.main import generate_all_data\n",
    "    data = generate_all_data()\n",
    "else:\n",
    "    print(\"Data already exists. Loading...\")\n",
    "    # Load common data\n",
    "    venues_df = pd.read_csv(os.path.join(data_dir, \"venues.csv\"))\n",
    "    users_df = pd.read_csv(os.path.join(data_dir, \"users.csv\"))\n",
    "    users_processed_df = pd.read_csv(os.path.join(data_dir, \"users_processed.csv\"))\n",
    "    seasonal_df = pd.read_csv(os.path.join(data_dir, \"seasonal.csv\"))\n",
    "    weather_df = pd.read_csv(os.path.join(data_dir, \"weather.csv\"))\n",
    "    interactions_df = pd.read_csv(os.path.join(data_dir, \"interactions.csv\"))\n",
    "    \n",
    "    # Load base training data (first 2 years)\n",
    "    base_train_df = pd.read_csv(os.path.join(data_dir, \"interactions_base_train.csv\"))\n",
    "    \n",
    "    # Find all monthly evaluation files\n",
    "    eval_files = [f for f in os.listdir(data_dir) if f.startswith(\"interactions_eval_\") and f.endswith(\".csv\")]\n",
    "    eval_months = [f.replace(\"interactions_eval_\", \"\").replace(\".csv\", \"\") for f in eval_files]\n",
    "    eval_months.sort()\n",
    "    \n",
    "    print(f\"Found {len(eval_months)} monthly evaluation sets: {eval_months}\")\n",
    "    \n",
    "    # Load the first month's evaluation data for demonstration\n",
    "    if eval_months:\n",
    "        first_month = eval_months[0]\n",
    "        eval_df = pd.read_csv(os.path.join(data_dir, f\"interactions_eval_{first_month}.csv\"))\n",
    "        train_df = pd.read_csv(os.path.join(data_dir, f\"interactions_train_{first_month}.csv\"))\n",
    "    else:\n",
    "        # Fallback to base training data\n",
    "        eval_df = None\n",
    "        train_df = base_train_df\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    \n",
    "    data = {\n",
    "        \"venues\": venues_df,\n",
    "        \"users\": users_df,\n",
    "        \"users_processed\": users_processed_df,\n",
    "        \"seasonal\": seasonal_df,\n",
    "        \"weather\": weather_df,\n",
    "        \"interactions\": interactions_df,\n",
    "        \"interactions_base_train\": base_train_df,\n",
    "        \"interactions_train\": train_df,\n",
    "        \"interactions_eval\": eval_df,\n",
    "        \"eval_months\": eval_months\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the Data\n",
    "\n",
    "Let's explore the generated data to understand its structure and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Venue Data\n",
    "\n",
    "First, let's look at the venue data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display venue data\n",
    "print(f\"Number of venues: {len(data['venues'])}\")\n",
    "data['venues'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Venue type distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data['venues'], x='venue_type')\n",
    "plt.title('Venue Type Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Amenity availability\n",
    "amenities = ['pool', 'beach_access', 'spa', 'gym', 'hot_tub', 'food_service', 'bar']\n",
    "amenity_availability = {amenity: data['venues'][amenity].mean() for amenity in amenities if amenity in data['venues'].columns}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=list(amenity_availability.keys()), y=list(amenity_availability.values()))\n",
    "plt.title('Amenity Availability')\n",
    "plt.ylabel('Percentage of Venues')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Price distribution by venue type\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=data['venues'], x='venue_type', y='day_pass_price')\n",
    "plt.title('Day Pass Price by Venue Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Seasonal Data\n",
    "\n",
    "Let's examine how amenity availability and pricing change by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display seasonal data\n",
    "print(f\"Number of seasonal records: {len(data['seasonal'])}\")\n",
    "data['seasonal'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Pool availability by season\n",
    "if 'pool_available' in data['seasonal'].columns:\n",
    "    pool_availability = data['seasonal'].groupby('season')['pool_available'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=pool_availability.index, y=pool_availability.values)\n",
    "    plt.title('Pool Availability by Season')\n",
    "    plt.ylabel('Percentage of Venues')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Seasonal price variation\n",
    "seasonal_price = data['seasonal'].groupby(['season', 'venue_id'])['seasonal_price'].mean().reset_index()\n",
    "base_price = data['venues'][['venue_id', 'day_pass_price']]\n",
    "price_comparison = seasonal_price.merge(base_price, on='venue_id')\n",
    "price_comparison['price_ratio'] = price_comparison['seasonal_price'] / price_comparison['day_pass_price']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=price_comparison, x='season', y='price_ratio')\n",
    "plt.axhline(y=1, color='r', linestyle='--')\n",
    "plt.title('Seasonal Price Ratio (Seasonal Price / Base Price)')\n",
    "plt.ylabel('Price Ratio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 User Interaction Data\n",
    "\n",
    "Now let's look at the user interaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display interaction data\n",
    "print(f\"Number of interactions: {len(data['interactions'])}\")\n",
    "data['interactions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Overall click-through rate\n",
    "ctr = data['interactions']['clicked'].mean()\n",
    "print(f\"Overall Click-Through Rate: {ctr:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CTR by position\n",
    "ctr_by_position = data['interactions'].groupby('position')['clicked'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=ctr_by_position.index, y=ctr_by_position.values)\n",
    "plt.title('Click-Through Rate by Position')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Click-Through Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CTR by season\n",
    "ctr_by_season = data['interactions'].groupby('season')['clicked'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=ctr_by_season.index, y=ctr_by_season.values)\n",
    "plt.title('Click-Through Rate by Season')\n",
    "plt.ylabel('Click-Through Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CTR by year and month\n",
    "if 'year' in data['interactions'].columns and 'month' in data['interactions'].columns:\n",
    "    # Create year_month column if it doesn't exist\n",
    "    if 'year_month' not in data['interactions'].columns:\n",
    "        data['interactions']['year_month'] = data['interactions']['year'].astype(str) + '_' + data['interactions']['month'].astype(str).str.zfill(2)\n",
    "    \n",
    "    ctr_by_month = data['interactions'].groupby('year_month')['clicked'].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(data=ctr_by_month, x='year_month', y='clicked')\n",
    "    plt.title('Click-Through Rate by Year-Month')\n",
    "    plt.xlabel('Year-Month')\n",
    "    plt.ylabel('Click-Through Rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CTR by distance\n",
    "# Note: distance_bucket is now created during data generation\n",
    "if 'distance_bucket' not in data['interactions'].columns:\n",
    "    data['interactions']['distance_bucket'] = pd.cut(\n",
    "        data['interactions']['distance_km'],\n",
    "        bins=[0, 1, 2, 5, 10, 20, 50],\n",
    "        labels=['0-1km', '1-2km', '2-5km', '5-10km', '10-20km', '20-50km']\n",
    "    )\n",
    "\n",
    "ctr_by_distance = data['interactions'].groupby('distance_bucket')['clicked'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=ctr_by_distance.index, y=ctr_by_distance.values)\n",
    "plt.title('Click-Through Rate by Distance')\n",
    "plt.ylabel('Click-Through Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Temporal Data Analysis\n",
    "\n",
    "Let's analyze how the data is distributed across the 3-year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if year and month columns exist\n",
    "if 'year' in data['interactions'].columns and 'month' in data['interactions'].columns:\n",
    "    # Count interactions by year\n",
    "    year_counts = data['interactions']['year'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=year_counts.index, y=year_counts.values)\n",
    "    plt.title('Interactions by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Interactions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Count interactions by year and month\n",
    "    if 'year_month' not in data['interactions'].columns:\n",
    "        data['interactions']['year_month'] = data['interactions']['year'].astype(str) + '_' + data['interactions']['month'].astype(str).str.zfill(2)\n",
    "    \n",
    "    month_counts = data['interactions']['year_month'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(x=month_counts.index, y=month_counts.values)\n",
    "    plt.title('Interactions by Year-Month')\n",
    "    plt.xlabel('Year-Month')\n",
    "    plt.ylabel('Number of Interactions')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Ranking Model\n",
    "\n",
    "Now let's train a ranking model using the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.modeling.feature_engineering import prepare_features\n",
    "from src.modeling.model import train_ranking_model, save_model\n",
    "\n",
    "# Prepare features for training\n",
    "print(\"Preparing features...\")\n",
    "train_features_df = prepare_features(\n",
    "    data['interactions_train'],\n",
    "    data['venues'],\n",
    "    data['users_processed'],\n",
    "    data['seasonal'],\n",
    "    data['weather']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "model, feature_cols = train_ranking_model(train_features_df)\n",
    "\n",
    "# Save model\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "save_model(model, feature_cols, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "train_features_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Model\n",
    "\n",
    "Let's evaluate the trained model on the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.modeling.evaluation import evaluate_model, generate_evaluation_report\n",
    "\n",
    "# Check if we have evaluation data\n",
    "if data['interactions_eval'] is not None:\n",
    "    eval_df = data['interactions_eval']\n",
    "else:\n",
    "    # Fallback to using a portion of the training data\n",
    "    print(\"No evaluation data found. Using a portion of training data for evaluation.\")\n",
    "    train_size = int(len(data['interactions_train']) * 0.8)\n",
    "    eval_df = data['interactions_train'].iloc[train_size:]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Evaluating model...\")\n",
    "metrics, results_df = evaluate_model(\n",
    "    model,\n",
    "    eval_df,\n",
    "    data['venues'],\n",
    "    data['users_processed'],\n",
    "    data['seasonal'],\n",
    "    data['weather'],\n",
    "    feature_cols\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"AUC: {metrics['auc']:.4f}\")\n",
    "print(f\"Average Precision: {metrics['average_precision']:.4f}\")\n",
    "print(f\"NDCG@5: {metrics['ndcg@5']:.4f}\")\n",
    "print(f\"NDCG@10: {metrics['ndcg@10']:.4f}\")\n",
    "print(f\"CTR@1: {metrics['ctr@1']:.4f}\")\n",
    "print(f\"CTR@5: {metrics['ctr@5']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot precision-recall curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(results_df['clicked'], results_df['predicted_score'])\n",
    "ap = average_precision_score(results_df['clicked'], results_df['predicted_score'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, lw=2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve (AP = {ap:.4f})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot score distribution by clicked status\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=results_df,\n",
    "    x='predicted_score',\n",
    "    hue='clicked',\n",
    "    bins=30,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title('Distribution of Predicted Scores by Clicked Status')\n",
    "plt.xlabel('Predicted Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "importance = model.get_score(importance_type='gain')\n",
    "importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Plot top 20 features\n",
    "top_features = importance[:20]\n",
    "feature_names = [f[0] for f in top_features]\n",
    "feature_scores = [f[1] for f in top_features]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=feature_scores, y=feature_names)\n",
    "plt.title('Top 20 Features by Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use the Model for Ranking Venues\n",
    "\n",
    "Now let's use the trained model to rank venues for a specific user and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.modeling.model import predict_rankings\n",
    "\n",
    "# Select a random session from the evaluation data\n",
    "if data['interactions_eval'] is not None:\n",
    "    session_id = data['interactions_eval']['session_id'].sample(1).iloc[0]\n",
    "    session_data = data['interactions_eval'][data['interactions_eval']['session_id'] == session_id]\n",
    "else:\n",
    "    # Fallback to using training data\n",
    "    session_id = data['interactions_train']['session_id'].sample(1).iloc[0]\n",
    "    session_data = data['interactions_train'][data['interactions_train']['session_id'] == session_id]\n",
    "\n",
    "print(f\"Selected session ID: {session_id}\")\n",
    "print(f\"Number of venues in session: {len(session_data)}\")\n",
    "\n",
    "# Get user ID and context information\n",
    "user_id = session_data['user_id'].iloc[0]\n",
    "season = session_data['season'].iloc[0]\n",
    "time_slot = session_data['time_slot'].iloc[0]\n",
    "\n",
    "print(f\"User ID: {user_id}\")\n",
    "print(f\"Season: {season}\")\n",
    "print(f\"Time slot: {time_slot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare features for the session\n",
    "session_features = prepare_features(\n",
    "    session_data,\n",
    "    data['venues'],\n",
    "    data['users_processed'],\n",
    "    data['seasonal'],\n",
    "    data['weather']\n",
    ")\n",
    "\n",
    "# Predict rankings\n",
    "ranked_venues = predict_rankings(model, session_features, feature_cols)\n",
    "\n",
    "# Sort by predicted score\n",
    "ranked_venues = ranked_venues.sort_values('predicted_score', ascending=False)\n",
    "\n",
    "# Display ranked venues\n",
    "display_cols = ['venue_id', 'clicked', 'predicted_score', 'predicted_rank',\n",
    "               'venue_type', 'star_rating', 'seasonal_price', 'vibe',\n",
    "               'distance_km', 'time_slot']\n",
    "\n",
    "ranked_venues[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare model ranking with original position\n",
    "comparison = ranked_venues[['venue_id', 'position', 'predicted_rank', 'clicked', 'predicted_score']]\n",
    "comparison = comparison.sort_values('position')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(comparison['position'], comparison['predicted_rank'], \n",
    "           c=comparison['clicked'].map({True: 'green', False: 'red'}),\n",
    "           s=100, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Original Position')\n",
    "plt.ylabel('Predicted Rank')\n",
    "plt.title('Original Position vs. Predicted Rank')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add diagonal line for reference\n",
    "max_val = max(comparison['position'].max(), comparison['predicted_rank'].max())\n",
    "plt.plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Clicked'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Not Clicked')\n",
    "]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monthly Evaluation\n",
    "\n",
    "Now let's demonstrate the monthly evaluation approach, where we train and evaluate models for each month of the evaluation year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.modeling.train import train_and_evaluate_all_months\n",
    "\n",
    "# Check if we have monthly evaluation data\n",
    "if 'eval_months' in data and data['eval_months']:\n",
    "    print(f\"Found {len(data['eval_months'])} monthly evaluation sets: {data['eval_months']}\")\n",
    "    \n",
    "    # We'll demonstrate the monthly evaluation process by training and evaluating for each month\n",
    "    # Note: This can be time-consuming, so we'll just show the process for a few months\n",
    "    sample_months = data['eval_months'][:3] if len(data['eval_months']) > 3 else data['eval_months']\n",
    "    \n",
    "    # Store results for each month\n",
    "    monthly_results = {}\n",
    "    \n",
    "    for year_month in sample_months:\n",
    "        print(f\"\\n=== Processing month: {year_month} ===\\n\")\n",
    "        \n",
    "        # Load training and evaluation data for this month\n",
    "        train_df = pd.read_csv(os.path.join(data_dir, f\"interactions_train_{year_month}.csv\"))\n",
    "        eval_df = pd.read_csv(os.path.join(data_dir, f\"interactions_eval_{year_month}.csv\"))\n",
    "        \n",
    "        print(f\"Training data size: {len(train_df)}\")\n",
    "        print(f\"Evaluation data size: {len(eval_df)}\")\n",
    "        \n",
    "        # Prepare features for training\n",
    "        print(\"Preparing features...\")\n",
    "        train_features_df = prepare_features(\n",
    "            train_df,\n",
    "            data['venues'],\n",
    "            data['users_processed'],\n",
    "            data['seasonal'],\n",
    "            data['weather']\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Training model...\")\n",
    "        model, feature_cols = train_ranking_model(train_features_df)\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"Evaluating model...\")\n",
    "        metrics, results_df = evaluate_model(\n",
    "            model,\n",
    "            eval_df,\n",
    "            data['venues'],\n",
    "            data['users_processed'],\n",
    "            data['seasonal'],\n",
    "            data['weather'],\n",
    "            feature_cols\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        monthly_results[year_month] = {\n",
    "            'model': model,\n",
    "            'feature_cols': feature_cols,\n",
    "            'metrics': metrics,\n",
    "            'results_df': results_df\n",
    "        }\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nEvaluation Metrics for {year_month}:\")\n",
    "        print(f\"AUC: {metrics['auc']:.4f}\")\n",
    "        print(f\"Average Precision: {metrics['average_precision']:.4f}\")\n",
    "        print(f\"NDCG@5: {metrics['ndcg@5']:.4f}\")\n",
    "        print(f\"NDCG@10: {metrics['ndcg@10']:.4f}\")\n",
    "        print(f\"CTR@1: {metrics['ctr@1']:.4f}\")\n",
    "        print(f\"CTR@5: {metrics['ctr@5']:.4f}\")\n",
    "else:\n",
    "    print(\"No monthly evaluation data found. Run the pipeline with --monthly-eval flag to generate it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Compare Performance Across Months\n",
    "\n",
    "Let's compare the model performance across different months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if we have monthly results\n",
    "if 'monthly_results' in locals() and monthly_results:\n",
    "    # Extract metrics for each month\n",
    "    months = list(monthly_results.keys())\n",
    "    auc_values = [monthly_results[m]['metrics']['auc'] for m in months]\n",
    "    ndcg5_values = [monthly_results[m]['metrics']['ndcg@5'] for m in months]\n",
    "    ctr1_values = [monthly_results[m]['metrics']['ctr@1'] for m in months]\n",
    "    ctr5_values = [monthly_results[m]['metrics']['ctr@5'] for m in months]\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Month': months,\n",
    "        'AUC': auc_values,\n",
    "        'NDCG@5': ndcg5_values,\n",
    "        'CTR@1': ctr1_values,\n",
    "        'CTR@5': ctr5_values\n",
    "    })\n",
    "    \n",
    "    # Display summary table\n",
    "    summary_df\n",
    "    \n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # AUC plot\n",
    "    axes[0, 0].plot(months, auc_values, marker='o')\n",
    "    axes[0, 0].set_title('AUC by Month')\n",
    "    axes[0, 0].set_xlabel('Month')\n",
    "    axes[0, 0].set_ylabel('AUC')\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # NDCG@5 plot\n",
    "    axes[0, 1].plot(months, ndcg5_values, marker='o', color='orange')\n",
    "    axes[0, 1].set_title('NDCG@5 by Month')\n",
    "    axes[0, 1].set_xlabel('Month')\n",
    "    axes[0, 1].set_ylabel('NDCG@5')\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # CTR@1 plot\n",
    "    axes[1, 0].plot(months, ctr1_values, marker='o', color='green')\n",
    "    axes[1, 0].set_title('CTR@1 by Month')\n",
    "    axes[1, 0].set_xlabel('Month')\n",
    "    axes[1, 0].set_ylabel('CTR@1')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # CTR@5 plot\n",
    "    axes[1, 1].plot(months, ctr5_values, marker='o', color='red')\n",
    "    axes[1, 1].set_title('CTR@5 by Month')\n",
    "    axes[1, 1].set_xlabel('Month')\n",
    "    axes[1, 1].set_ylabel('CTR@5')\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No monthly results available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Feature Importance Across Months\n",
    "\n",
    "Let's compare how feature importance changes across different months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if we have monthly results\n",
    "if 'monthly_results' in locals() and monthly_results:\n",
    "    # Get top 10 features for each month\n",
    "    top_features_by_month = {}\n",
    "    \n",
    "    for month, results in monthly_results.items():\n",
    "        model = results['model']\n",
    "        importance = model.get_score(importance_type='gain')\n",
    "        importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        top_features_by_month[month] = importance\n",
    "    \n",
    "    # Plot top features for each month\n",
    "    fig, axes = plt.subplots(len(top_features_by_month), 1, figsize=(12, 5*len(top_features_by_month)))\n",
    "    \n",
    "    for i, (month, features) in enumerate(top_features_by_month.items()):\n",
    "        feature_names = [f[0] for f in features]\n",
    "        feature_scores = [f[1] for f in features]\n",
    "        \n",
    "        ax = axes[i] if len(top_features_by_month) > 1 else axes\n",
    "        sns.barplot(x=feature_scores, y=feature_names, ax=ax)\n",
    "        ax.set_title(f'Top 10 Features by Importance - {month}')\n",
    "        ax.set_xlabel('Importance Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No monthly results available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Venue Locations\n",
    "\n",
    "Let's visualize the venue locations for a specific city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.utils.visualization import plot_venue_locations\n",
    "\n",
    "# Get user's city\n",
    "user_city = data['users'][data['users']['user_id'] == user_id]['home_city'].iloc[0]\n",
    "print(f\"User's city: {user_city}\")\n",
    "\n",
    "# Plot venue locations\n",
    "plot_venue_locations(data['venues'], data['users'], city=user_city)\n",
    "plt.title(f'Venue Locations in {user_city}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Seasonal Availability Analysis\n",
    "\n",
    "Let's analyze how amenity availability changes by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.utils.visualization import plot_seasonal_availability\n",
    "\n",
    "# Plot seasonal availability for different amenities\n",
    "amenities = ['pool', 'beach_access', 'spa', 'gym', 'hot_tub']\n",
    "\n",
    "fig, axes = plt.subplots(len(amenities), 1, figsize=(12, 4*len(amenities)))\n",
    "\n",
    "for i, amenity in enumerate(amenities):\n",
    "    try:\n",
    "        plot_seasonal_availability(data['seasonal'], amenity=amenity, ax=axes[i])\n",
    "    except (KeyError, ValueError) as e:\n",
    "        axes[i].text(0.5, 0.5, f\"No data available for {amenity}\", \n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "        axes[i].set_title(f'Seasonal Availability of {amenity.capitalize()}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the hotel ranking system for day-access amenities. We've shown how to:\n",
    "\n",
    "1. Generate synthetic data spanning 3 years\n",
    "2. Explore the data to understand its characteristics\n",
    "3. Train a ranking model using XGBoost\n",
    "4. Evaluate the model's performance\n",
    "5. Use the model to rank venues for a specific user and context\n",
    "6. Perform monthly evaluation to track model performance over time\n",
    "7. Visualize venue locations and seasonal availability\n",
    "\n",
    "The model takes into account various factors including:\n",
    "- User preferences and history\n",
    "- Venue attributes and amenities\n",
    "- Seasonal availability and pricing\n",
    "- Weather conditions\n",
    "- Location proximity\n",
    "- Time slot availability\n",
    "\n",
    "This approach provides a personalized ranking of venues based on the specific context and user preferences, and the monthly evaluation approach allows us to track how model performance changes over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
